{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import common.utils as utils\n",
    "from lstm.train import construct_graph\n",
    "\n",
    "num_steps = 100\n",
    "max_length = 200\n",
    "\n",
    "def update_feed():\n",
    "  input = np.zeros([1, num_steps], dtype=np.int64)\n",
    "  dictionary = utils.load_dictionary()\n",
    "  input[b, 0] = dictionary['<bof>']\n",
    "  return input\n",
    "\n",
    "def sample(prediction):\n",
    "  return np.random.choice(prediction.size, (), p=prediction)\n",
    "\n",
    "def format_feed(input):\n",
    "  \"\"\"Format input to feed to LSTM\n",
    "  Implicitly batch_size = 1\n",
    "  \"\"\"\n",
    "  length = len(input)\n",
    "  if length < num_steps:\n",
    "    return [input + [0]*(num_steps-length)]\n",
    "  else:\n",
    "    return [input[-num_steps:]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, array(5775)]\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "optimizer, loss, inputs, probs, learning_rate, dictionary, saver, summary = construct_graph(graph)\n",
    "with tf.Session(graph=graph) as sess:\n",
    "  saver.restore(sess, \"checkpoints/model.ckpt\")\n",
    "  coord = tf.train.Coordinator()\n",
    "  threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "  dictionary = utils.load_dictionary()\n",
    "  feed_input = []\n",
    "  sample_character = dictionary['<bof>']\n",
    "  feed_input.append(sample_character) # begin with <bof>\n",
    "  try:\n",
    "    for i in range(1):\n",
    "      feed_dict = {inputs: format_feed(feed_input)} # feed last <num_steps> words\n",
    "      test_probs = probs.eval(feed_dict=feed_dict) # predict\n",
    "      sample_character = sample(test_probs) # sampling\n",
    "      feed_input.append(sample_character) # update feed\n",
    "      if sample_character == '<eof>': # stop sampling when meet <eof>\n",
    "        break\n",
    "  except Exception as e:\n",
    "    print('Exception: {}'.format(e.args))\n",
    "    coord.request_stop(e)\n",
    "\n",
    "  print(feed_input)\n",
    "  # utils.print_data(feed_input, pretty=True)\n",
    "\n",
    "  coord.request_stop()\n",
    "  coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 20368)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17821"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(test_probs[0])[()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16365\n"
     ]
    }
   ],
   "source": [
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
